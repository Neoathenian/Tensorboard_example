{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Rafa\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:72: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name    | Type             | Params\n",
      "----------------------------------------------\n",
      "0  | conv1   | Conv2d           | 448   \n",
      "1  | conv2   | Conv2d           | 4.6 K \n",
      "2  | conv3   | Conv2d           | 18.5 K\n",
      "3  | bn1     | InstanceNorm2d   | 32    \n",
      "4  | bn2     | InstanceNorm2d   | 64    \n",
      "5  | bn3     | InstanceNorm2d   | 128   \n",
      "6  | pool    | MaxPool2d        | 0     \n",
      "7  | fc1     | Linear           | 16.4 K\n",
      "8  | fc3     | Linear           | 585   \n",
      "9  | softmax | Softmax          | 0     \n",
      "10 | loss    | CrossEntropyLoss | 0     \n",
      "----------------------------------------------\n",
      "40.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "40.8 K    Total params\n",
      "0.163     Total estimated model params size (MB)\n",
      "c:\\Users\\Rafa\\miniconda3\\lib\\site-packages\\lightning_fabric\\loggers\\csv_logs.py:188: UserWarning: Experiment logs directory logs\\Modelo_1\\version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\Rafa\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4caace338e4ca3bf8fc14ae2773a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rafa\\miniconda3\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\Rafa\\miniconda3\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: Average precision score for one or more classes was `nan`. Ignoring these classes in macro-average\n",
      "  warnings.warn(*args, **kwargs)\n",
      "c:\\Users\\Rafa\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\result.py:212: UserWarning: You called `self.log('train_mcc', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': tensor(1.7386, device='cuda:0'), 'train_acc': tensor(0.6332, device='cuda:0'), 'train_precision': tensor(0.6332, device='cuda:0'), 'train_recall': tensor(0.6332, device='cuda:0'), 'train_f1': tensor(0.6332, device='cuda:0'), 'train_specificity': tensor(0.9541, device='cuda:0'), 'train_mcc': tensor(-1.8837e-05, device='cuda:0'), 'train_auroc': tensor(0.2340, device='cuda:0'), 'train_aupr': tensor(0.2863, device='cuda:0')}\n",
      "[]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2349, device='cuda:0'), 'train_aupr': tensor(0.2830, device='cuda:0')}\n",
      "[1.738629937171936]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2285, device='cuda:0'), 'train_aupr': tensor(0.2816, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2329, device='cuda:0'), 'train_aupr': tensor(0.2817, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2276, device='cuda:0'), 'train_aupr': tensor(0.2857, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2336, device='cuda:0'), 'train_aupr': tensor(0.2821, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2316, device='cuda:0'), 'train_aupr': tensor(0.2873, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2326, device='cuda:0'), 'train_aupr': tensor(0.2789, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2222, device='cuda:0'), 'train_aupr': tensor(0.2845, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2385, device='cuda:0'), 'train_aupr': tensor(0.2907, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2296, device='cuda:0'), 'train_aupr': tensor(0.2918, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2355, device='cuda:0'), 'train_aupr': tensor(0.2819, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2375, device='cuda:0'), 'train_aupr': tensor(0.2897, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2381, device='cuda:0'), 'train_aupr': tensor(0.2859, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2277, device='cuda:0'), 'train_aupr': tensor(0.2852, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2317, device='cuda:0'), 'train_aupr': tensor(0.2818, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2426, device='cuda:0'), 'train_aupr': tensor(0.3012, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2419, device='cuda:0'), 'train_aupr': tensor(0.2898, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2340, device='cuda:0'), 'train_aupr': tensor(0.2802, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2298, device='cuda:0'), 'train_aupr': tensor(0.2892, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2391, device='cuda:0'), 'train_aupr': tensor(0.2857, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2330, device='cuda:0'), 'train_aupr': tensor(0.2797, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2328, device='cuda:0'), 'train_aupr': tensor(0.2790, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428]\n",
      "{'train_loss': tensor(1.7297, device='cuda:0'), 'train_acc': tensor(0.6423, device='cuda:0'), 'train_precision': tensor(0.6423, device='cuda:0'), 'train_recall': tensor(0.6423, device='cuda:0'), 'train_f1': tensor(0.6423, device='cuda:0'), 'train_specificity': tensor(0.9553, device='cuda:0'), 'train_mcc': tensor(0., device='cuda:0'), 'train_auroc': tensor(0.2297, device='cuda:0'), 'train_aupr': tensor(0.3003, device='cuda:0')}\n",
      "[1.738629937171936, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296558618545532, 1.7296559810638428, 1.7296559810638428]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rafa\\miniconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Import the required callbacks\n",
    "from torchmetrics import AUROC\n",
    "from random import random\n",
    "\n",
    "\n",
    "from pytorch_lightning import Callback\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score, Specificity, AUROC, MatthewsCorrCoef, ConfusionMatrix, AUROC, AveragePrecision\n",
    "\n",
    "\n",
    "# Define the CNN architecture\n",
    "class Net(pl.LightningModule):\n",
    "    name=\"Modelo_1\"\n",
    "    num_classes=9\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn1 =  nn.InstanceNorm2d(16,eps=1.0e-05,momentum=0.1,affine=True,track_running_stats=False)\n",
    "        self.bn2 =  nn.InstanceNorm2d(32,eps=1.0e-05,momentum=0.1,affine=True,track_running_stats=False)\n",
    "        self.bn3 =  nn.InstanceNorm2d(64,eps=1.0e-05,momentum=0.1,affine=True,track_running_stats=False)\n",
    "\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        #self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(64, self.num_classes)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        self.loss=nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "        self.metrics_classification = {\n",
    "            'train_acc': Accuracy(num_classes=self.num_classes, task='multiclass'),\n",
    "            'train_precision': Precision(num_classes=self.num_classes, task='multiclass'),\n",
    "            'train_recall': Recall(num_classes=self.num_classes, task='multiclass'),\n",
    "            'train_f1': F1Score(num_classes=self.num_classes, task='multiclass'),\n",
    "            'train_specificity': Specificity(num_classes=self.num_classes, task='multiclass'),\n",
    "            'train_mcc': MatthewsCorrCoef(num_classes=self.num_classes, task='multiclass'),\n",
    "        }\n",
    "\n",
    "        self.metrics_probs={\n",
    "            'train_auroc': AUROC(num_classes=self.num_classes, task='multiclass'),\n",
    "            'train_aupr': AveragePrecision(num_classes=self.num_classes, task='multiclass'),\n",
    "        }\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)  # Get the batch size\n",
    "        x = self.pool(self.bn1(F.relu(self.conv1(x))))\n",
    "        x = self.pool(self.bn2(F.relu(self.conv2(x))))\n",
    "        x = self.pool(self.bn3(F.relu(self.conv3(x))))\n",
    "        x = x.view(batch_size, -1)  # Flatten the tensor without using x.view()\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y) #F.cross_entropy(y_hat, y)\n",
    "        self.log('train_loss', loss, on_epoch=True,on_step=False,prog_bar=True,logger=True)\n",
    "\n",
    "        # Compute and log additional metrics\n",
    "        preds = y_hat.argmax(dim=1)\n",
    "\n",
    "        for name, metric in self.metrics_classification.items():\n",
    "            self.log(name, metric.to(y.device)(preds, y), on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "\n",
    "        for name, metric in self.metrics_probs.items():\n",
    "            self.log(name, metric.to(y.device)(y_hat, y), on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01)\n",
    "        return optimizer\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        #Here´s the code for the validation step (right now it´s the same as the training step)\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y) #F.cross_entropy(y_hat, y)\n",
    "        self.log('val_loss', loss, on_epoch=True,on_step=False,prog_bar=True,logger=True)\n",
    "\n",
    "        # Compute and log additional metrics\n",
    "        preds = y_hat.argmax(dim=1)\n",
    "\n",
    "        for name, metric in self.metrics_classification.items():\n",
    "            self.log(name, metric.to(y.device)(preds, y), on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "\n",
    "        for name, metric in self.metrics_probs.items():\n",
    "            self.log(name, metric.to(y.device)(y_hat, y), on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        #Here´s the code for the test step (right now it´s the same as the training step)\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y) #F.cross_entropy(y_hat, y)\n",
    "        self.log('test_loss', loss, on_epoch=True,on_step=False,prog_bar=True,logger=True)\n",
    "\n",
    "        # Compute and log additional metrics\n",
    "        preds = y_hat.argmax(dim=1)\n",
    "\n",
    "        for name, metric in self.metrics_classification.items():\n",
    "            self.log(name, metric.to(y.device)(preds, y), on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "\n",
    "        for name, metric in self.metrics_probs.items():\n",
    "            self.log(name, metric.to(y.device)(y_hat, y), on_epoch=True, on_step=False, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(16),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.02, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(16),\n",
    "        transforms.CenterCrop(16),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Assuming the images are in a directory named \"data\", with two subdirectories \"train\" and \"val\"\n",
    "data_dir = 'Data'\n",
    "image_datasets = {x: ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=50, shuffle=True) for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LossPlotter(Callback):\n",
    "    #The idea here was to plot interactively in vs code (I found it easier using tensorboard so I will not be doing this). It is interesting it´s ability to do stuff after each epoch (maybe the trainer itself can do that)\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.losses = []\n",
    "#        self.fig, self.ax = plt.subplots()\n",
    "\n",
    "\n",
    "    def on_train_epoch_end  (self, trainer, pl_module):\n",
    "        print(trainer.callback_metrics)\n",
    "        # Get the current loss\n",
    "        # Get the current loss\n",
    "        current_loss = trainer.callback_metrics['train_loss'].item()\n",
    "        print(self.losses)\n",
    "        self.losses.append(current_loss)\n",
    "\n",
    "\n",
    "loss_plotter = LossPlotter()\n",
    "\n",
    "\n",
    "# Init our model\n",
    "model = Net()\n",
    "\n",
    "# Init DataLoader from training set\n",
    "train_loader = dataloaders['train']\n",
    "\n",
    "\n",
    "loss_plotter = LossPlotter()\n",
    "#This is the important logger as it sends it as a tensorboard file\n",
    "logger = TensorBoardLogger(\"logs\", name=\"my_model\")\n",
    "#Using this to store the metrics as a csv for easy to read use\n",
    "logger_csv = CSVLogger(\"logs\", name=model.name)\n",
    "\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(logger=[logger,logger_csv],max_epochs=100, devices=1, accelerator=\"gpu\", callbacks=[loss_plotter])\n",
    "\n",
    "\n",
    "#val_loader = dataloaders['val']\n",
    "trainer.fit(model,train_loader)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
